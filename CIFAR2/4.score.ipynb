{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import spearmanr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar2'\n",
    "dataset_type = 'test'\n",
    "\n",
    "method = 'das'\n",
    "proj_dim = 4096\n",
    "selected_timesteps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(idx_train): 5000\n"
     ]
    }
   ],
   "source": [
    "train_index_path = f'./data/idx-train.pkl'\n",
    "# Load train index\n",
    "with open(train_index_path, 'rb')  as handle:\n",
    "    idx_train = pickle.load(handle)\n",
    "print(\"len(idx_train):\", len(idx_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lds_mask_array.shape: (256, 5000)\n"
     ]
    }
   ],
   "source": [
    "# load lds subset index\n",
    "mask_array_list = []\n",
    "for i in range(256):\n",
    "    with open(f'./data/lds-val/sub-idx-{i}.pkl', 'rb')  as handle:\n",
    "        sub_idx_train = pickle.load(handle)\n",
    "    mask_array = np.in1d(idx_train, sub_idx_train)\n",
    "    mask_array_list.append(mask_array)\n",
    "lds_mask_array = np.stack(mask_array_list)\n",
    "print(\"lds_mask_array.shape:\", lds_mask_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lds subset model output\n",
    "loss_array_list = []\n",
    "for i in range(256):\n",
    "    \n",
    "    for seed in [0,1,2]:\n",
    "        for e_seed in [0,1,2]:\n",
    "            with open(f'./saved/errors/lds-val/model-{i}-{seed}/{dataset_type}-es{e_seed}.pkl', 'rb')  as handle:\n",
    "                # MSE loss\n",
    "                loss_list = pickle.load(handle)\n",
    "            margins = np.concatenate(loss_list, axis=-1)\n",
    "\n",
    "            if (seed == 0):\n",
    "                loss_array = margins\n",
    "            else:\n",
    "                loss_array += margins\n",
    "\n",
    "    loss_array = loss_array/3*3\n",
    "\n",
    "    loss_array_list.append(loss_array) \n",
    "\n",
    "lds_loss_array = np.stack(loss_array_list)\n",
    "print(\"lds_loss_array.shape:\", lds_loss_array.shape)\n",
    "\n",
    "lds_testset_correctness = lds_loss_array.mean(axis=1)\n",
    "print(\"lds_testset_correctness.shape:\", lds_testset_correctness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grad\n",
    "train_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    train_grad_seed = np.memmap(\n",
    "        f'./saved/grad/model-{seed}/ddpm-{method}-train-t{selected_timesteps}-d{proj_dim}-es0.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(5000, proj_dim)\n",
    "    )\n",
    "    train_grad_list.append(train_grad_seed)\n",
    "train_grad = np.stack(train_grad_list)\n",
    "print(\"train_grad.shape:\", train_grad.shape)\n",
    "train_grad = torch.from_numpy(train_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grad_list = []\n",
    "for seed in [0,1,2]:\n",
    "    test_grad_seed = np.memmap(\n",
    "        f'./saved/grad/model-{seed}/ddpm-{method}-{dataset_type}-t{selected_timesteps}-d{proj_dim}-es0.npy', \n",
    "        dtype=np.float32, \n",
    "        mode='r',\n",
    "        shape=(1000, proj_dim)\n",
    "    )\n",
    "    test_grad_list.append(test_grad_seed)\n",
    "test_grad = np.stack(test_grad_list)\n",
    "print(\"test_grad.shape:\", test_grad.shape)\n",
    "test_grad = torch.from_numpy(test_grad).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training set error\n",
    "train_error_list = []\n",
    "\n",
    "for seed in [0,1,2]:\n",
    "    with open(f'./saved/errors/model-{seed}/train-es0.pkl', 'rb')  as handle:\n",
    "        # MSE loss\n",
    "        error_list = pickle.load(handle)\n",
    "    error_array = np.concatenate(error_list, axis=-1)\n",
    "    error_array = error_array.sqrt()\n",
    "    \n",
    "    if (seed == 0):\n",
    "        train_error = error_array\n",
    "    else:\n",
    "        train_error += error_array\n",
    "\n",
    "train_error = train_error/3\n",
    "print(\"train_error.shape:\", train_error.shape)\n",
    "\n",
    "train_error_diag = np.diag(train_error)\n",
    "print(\"train_error_diag.shape:\", train_error_diag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the score\n",
    "lds_list = []\n",
    "lamb_list = [\n",
    "        1e-2, 2e-2, 5e-2,\n",
    "        1e-1, 2e-1, 5e-1,\n",
    "        1e0, 2e0, 5e0,\n",
    "        1e1, 2e1, 5e1,\n",
    "        1e2, 2e2, 5e2,\n",
    "        1e3, 2e3, 5e3, \n",
    "        1e4, 2e4, 5e4, \n",
    "        1e5, 2e5, 5e5, \n",
    "        1e6, 2e6, 5e6, \n",
    "    ]\n",
    "\n",
    "rs_list = []\n",
    "ps_list = []\n",
    "best_scores = None\n",
    "best_lds = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xtx(grads):\n",
    "    proj_dim = grads.shape[1]\n",
    "    result = torch.zeros(\n",
    "        proj_dim, proj_dim, dtype=torch.float16, device='cuda'\n",
    "    )\n",
    "    blocks = torch.split(grads, split_size_or_sections=20000, dim=0)\n",
    "\n",
    "    for block in blocks:\n",
    "        result += block.T @ block\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_xtx_inv(xtx, lambda_reg):\n",
    "    xtx_reg = xtx + lambda_reg * torch.eye(\n",
    "        xtx.size(0), device=xtx.device, dtype=xtx.dtype\n",
    "    )\n",
    "    xtx_inv = torch.linalg.inv(xtx_reg.to(torch.float32))\n",
    "\n",
    "    xtx_inv /= xtx_inv.abs().mean()\n",
    "\n",
    "    return xtx_inv.to(torch.float16)\n",
    "\n",
    "\n",
    "def get_A_B(A, B, batch_size=20000):\n",
    "\n",
    "    blocks = torch.split(A, split_size_or_sections=batch_size, dim=0)\n",
    "    result = torch.empty(\n",
    "        (A.shape[0], B.shape[1]), dtype=torch.float16, device=A.device\n",
    "    )\n",
    "\n",
    "    for i, block in enumerate(blocks):\n",
    "        start = i * batch_size\n",
    "        end = min(A.shape[0], (i + 1) * batch_size)\n",
    "        result[start:end] = block @ B\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for lamb in lamb_list:\n",
    "\n",
    "    scores_list = []\n",
    "\n",
    "    for seed in [0,1,2]:\n",
    "\n",
    "        train_grad_seed = train_grad[seed]\n",
    "        test_grad_seed = test_grad[seed]\n",
    "        kernel = get_xtx(train_grad_seed)\n",
    "        kernel_inv = get_xtx_inv(kernel, lamb)\n",
    "\n",
    "        if method == 'dtrak':\n",
    "            features = get_A_B(train_grad_seed, kernel_inv)\n",
    "            scores_seed = get_A_B(test_grad_seed, features.T)\n",
    "\n",
    "        elif method == 'das1':\n",
    "            features = get_A_B(train_grad_seed, kernel_inv)\n",
    "            scores_seed = get_A_B(test_grad_seed, features.T)\n",
    "            scores_seed = scores_seed@train_error_diag\n",
    "            scores_seed = scores_seed**2\n",
    "\n",
    "        elif method == 'das0':\n",
    "            features = get_A_B(train_grad_seed, kernel_inv)\n",
    "            hat_matrix = get_A_B(train_grad_seed, features.T)\n",
    "            hat_value = torch.diag(hat_matrix)\n",
    "            features = features/(1-hat_value)\n",
    "            scores_seed = get_A_B(test_grad_seed, features.T)\n",
    "            scores_seed = scores_seed@train_error_diag\n",
    "            scores_seed = scores_seed**2\n",
    "\n",
    "        scores_seed = scores_seed.cpu().numpy()\n",
    "        scores_list.append(scores_seed)\n",
    "    \n",
    "    scores = np.stack(scores_list)\n",
    "    scores = scores.mean(axis=0)\n",
    "\n",
    "    margins = lds_testset_correctness\n",
    "    infl_est_ = -scores\n",
    "    preds = lds_mask_array @ infl_est_.T\n",
    "\n",
    "    # compute lds score\n",
    "    rs = []\n",
    "    ps = []\n",
    "\n",
    "    for ind in range(1000):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, ind])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean():.3f} (avg p value {ps.mean():.6f})')\n",
    "\n",
    "    rs_list.append(rs.mean())   \n",
    "    ps_list.append(ps.mean())\n",
    "\n",
    "    if rs.mean()>best_lds:\n",
    "        best_scores = scores\n",
    "        best_lds = rs.mean()\n",
    "\n",
    "print(f'Best score: {best_lds:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
